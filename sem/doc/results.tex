\chapter{Results}
\label{chapter:results}

In this chapter we will analyze with which accuracy the algorithm from chapter~\ref{chapter:data_and_algorithm} classifies sleep stages. We will have a look into which frequencies differ most between the stages and whether the principal components of the PCA uses the same frequencies.

\section{Compression of Data}
From section~\ref{chapter:principal_component_analysis} we know that it is possible to use PCA to reduce dimensions of data. We want to know how much information is still present in the compressed data. This can be calculated by testing how many dimensions it takes to retain a certain amount of variance in the data.

We find the first index for which the sum of eigenvalues from the PCA is bigger than a certain percentage. The output for a few values are shown in table~\ref{tab:explained_variance}. As only few dimensions are needed to preserve 90\% of variance, which in our case means information, the PCA can successfully be used as a way to reduce the dimensions.

\begin{table}
	\centering
	\begin{tabular}{c|c}
		percentage of variance & number of dimensions needed \\
		\hline
		50\% & 1 out of 3000 \\
		80\% & 4 out of 3000 \\
		90\% & 26 out of 3000 \\
		95\% & 60 out of 3000 \\
	\end{tabular}
	\caption{Percentage of variance retained after reducing the dimension.}
	\label{tab:explained_variance}
\end{table}

\section{Testing the Accuracy}
To test the accuracy of the algorithm from section~\ref{sec:algorithm} we divide the dataset into two partitions, one for training the PCA and one for validating the results. The training data contains 11 of the 14 patients and the validation data contains the other 3 patients.

First the training data is used to calculate the principal components of the PCA. Then the validation data is transformed according to the principal components. Both the training and validation data are reduced to 26 dimensions, as we know that means only about 10\% of variance is lost. Lastly we use the k-nearest-neighbor algorithm to estimate the sleep stage of the validation data and compare it to the true classification. This is the algorithm~\ref{alg:gues_sleep_stage}.

When guessing the sleep stage we expect an accuracy of 20\%, as there are five different stages. For better comparison of the accuracy achieved, we run an algorithm, that does not use PCA, but otherwise follow the same logic. In comparison to algorithm~\ref{alg:gues_sleep_stage} the algorithm~\ref{alg:gues_sleep_stage_without_PCA} does not reduce dimensions, as there is no clear way of doing this without using PCA.

\begin{algorithm}
	\caption{Get estimate for sleep stage without PCA}\label{alg:gues_sleep_stage_without_PCA}
	\begin{algorithmic}
		\Require{EEG recording of sleep}
		\For{each 30s segment}
		\State Do FFT on the segment
		\State Do k nearest neighbor
		\State Save the result of k nearest neighbor
		\EndFor
		\State \Return results of k nearest neighbor
	\end{algorithmic}
\end{algorithm}

We test different values for $k$ of the k-nearest-neighbor algorithm. Table~\ref{tab:error_validation_overview} gives a overview of the accuracy achieved with and without PCA and different values for $k$. For every value of $k$ using PCA improves the accuracy.

\begin{table}
	\centering
	\begin{tabular}{c|c|c}
		k & accuracy with PCA & accuracy without PCA \\
		\hline
		1  & 40.88\% & 41.67\% \\
		5  & 45.28\% & 48.23\% \\
		10 & 45.72\% & 49.73\% \\
		15 & 45.62\% & 49.11\% \\
		20 & 45.62\% & 48.45\% \\
		25 & 44.93\% & 47.66\% \\
		30 & 44.81\% & 47.73\% \\
		35 & 44.43\% & 47.13\% \\
	\end{tabular}
	\caption{Overview of accuracy achieved with different values for k of k-nearest-neighbor.}
	\label{tab:error_validation_overview}
\end{table}

Using $k=10$ yields the best outcome in this limited validation set. Out of 3187 30 second segments the algorithm estimated the correct one 1457 times, which corresponds to a success rate of 45,72\%. Table~\ref{tab:error_validation} shows the outcome in more detail.

\begin{table}
	\centering
	\begin{subtable}{0.48\textwidth}
		\begin{tabular}{c|ccccc}
			    & S3  & S2  & S1 & REM & awake \\
			\hline
			S3 & 280  & 37  & 0  & 1  & 7 \\
			S2 & 401  & 634  & 8  & 176  & 35 \\
			S1 & 0  & 11  & 7  & 20  & 8 \\
			REM & 119  & 608  & 67  & 464  & 111 \\
			awake & 13  & 64  & 13  & 31  & 72 \\
		\end{tabular}
	\end{subtable}
	\hfill
	\begin{subtable}{0.48\textwidth}
		\begin{tabular}{c|ccccc}
			   & S3  & S2  & S1 & REM & awake \\
			\hline
			S3 & 225  & 25  & 0  & 0  & 5 \\
			S2 & 384  & 666  & 4  & 22  & 24 \\
			S1 & 0  & 15  & 5  & 16  & 13 \\
			REM & 196  & 615  & 82  & 635  & 137 \\
			awake & 8  & 33  & 4  & 19  & 54 \\
		\end{tabular}
	\end{subtable}
	
	\caption{The left table shows output for the algorithm using PCA, while the right table is from the algorithm that does not use PCA. Both tables show the number of sleep stages assigned to each stage, with the true value corresponding to the column and the estimate from the algorithm corresponding to the row. For both tables $k=10$.}
	\label{tab:error_validation}
\end{table}


\section{Rhythm Analysis}
There are four rhythms observed in the EEG\cite[chapter~11]{Ganong1997}. These rhythms differ in the frequency and are characterized as

\begin{itemize}
	\item Alpha: 8 - 12 Hz
	\item Beta: 18 - 30 Hz
	\item Theta: 4 - 7 Hz
	\item Delta: $<$ 4 Hz
\end{itemize}

It is easy to analyze the presence of these rhythms when looking at the fourier transformed data, as shown in figure~\ref{fig:eeg_with_rhythm}.

\begin{figure}
	\centering	
	\begin{tikzpicture}
		\begin{axis}[xlabel=Frequency (Hz), ylabel=Amplitude, width=\textwidth, height=0.3\textwidth]			
			\addplot+ [red, opacity=0.3, fill=red!90!black, no marks] coordinates 
			{(8,0.000002)   (12,0.000002)} |- (axis cs:8,0) -- cycle;
			
			\addplot+ [red, opacity=0.3, fill=red!90!black, no marks] coordinates 
			{(18,0.000002)   (30,0.000002)} |- (axis cs:18,0) -- cycle;
			
			\addplot+ [red, opacity=0.3, fill=red!90!black, no marks] coordinates 
			{(4.1,0.000002)   (7,0.000002)} |- (axis cs:4.1,0) -- cycle;
			
			\addplot+ [red, opacity=0.3, fill=red!90!black, no marks] coordinates 
			{(0,0.000002)   (3.9,0.000002)} |- (axis cs:0,0) -- cycle;
			
			\addplot+ [no marks, color=black] table[col sep=comma] {figs/fft_output.csv};
		\end{axis}
	\end{tikzpicture}
	
	\caption{Fourier transformed data with rhythms highlighted.}
	\label{fig:eeg_with_rhythm}
\end{figure}

We can now see if the output of the PCA gives importance to these rhythms. In figure~\ref{fig:pc_analysis} the sum of the absolute values of the first 26 principal components is shown. We chose 26 as from table~\ref{tab:explained_variance} we gather that 90\% of the variance is preserved. The most emphasis is given on the values from the theta rhythm. This was expected as the amplitudes in the FFT output are the highest in this region and we did not normalize the data before doing PCA.

\begin{figure}
	\centering	
	\begin{tikzpicture}
		\begin{axis}[xlabel=Frequency (Hz), ylabel=Amplitude, width=\textwidth, height=0.3\textwidth]			
			\addplot+ [red, opacity=0.3, fill=red!90!black, no marks] coordinates 
			{(8,4)   (12,4)} |- (axis cs:8,0) -- cycle;
			
			\addplot+ [red, opacity=0.3, fill=red!90!black, no marks] coordinates 
			{(18,4)   (30,4)} |- (axis cs:18,0) -- cycle;
			
			\addplot+ [red, opacity=0.3, fill=red!90!black, no marks] coordinates 
			{(4.1,4)   (7,4)} |- (axis cs:4.1,0) -- cycle;
			
			\addplot+ [red, opacity=0.3, fill=red!90!black, no marks] coordinates 
			{(0,4)   (3.9,4)} |- (axis cs:0,0) -- cycle;
			
			\addplot+ [no marks, color=black] table[col sep=comma] {figs/pc_analysis.csv};
		\end{axis}
	\end{tikzpicture}
	
	\caption{Sum of the absolute values of the first 26 principal components.}
	\label{fig:pc_analysis}
\end{figure}

